---
title: "Example Workflow"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Sample_Workflow}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```
### Introduction
This vignette goes through an example workflow using the `epictope` package. `epictope` facilitates the identification of optimal tagging locations for proteins of interest. Optimal locations are identified by considering four features; sequence conservation, secondary structure, solvent accessibility, and disordered binding regions. These four features are factored into a scoring function that calculates a cumulative score for each position in the protein. The weight of each feature and how they contribute to the final score can be defined by the user. Below, we work through a simple example of this workflow for a protein of interest.


### Dependencies
To calculate the multiple sequence alignment and secondary characteristics, `epictope` relies on local installs of BLAST, muscle, and dssp. These packages can be installed using conda, an open-source package management system and environment management system that runs on Windows, macOS, and Linux. Conda installers can be found at the Anaconda [website](https://www.anaconda.com/). Once installed, you may run the follow commands to install the requisite packages. These commands will create a conda environment named "epictope", and install the requisite packages into that environment. Alternative ways to install `epictope` dependencies are can be found [here](https://github.com/henrichung/epitope_tag#dependencies)

```{r, eval = FALSE}
conda create -n epictope
conda activate epictope
conda install -c bioconda blast
conda install -c bioconda muscle
conda install -c salilab dssp
conda install -c conda-forge r-base
conda install -c r r-stringi
conda install -c r r-openssl
```

### Installation

The `epictope` package can be installed from github using the `remotes` or `devtools` package.

```{r, eval = FALSE}
install.packages("devtools")
devtools::install_github("henrichung/epitope_tag")
```

#### Verify installation
To check if `epictope` has been installed correctly, we can attempt the load the package using "library()". If successful, the command should run without any further messages to the console. Once `epictope` has been loaded, we can use the provided ".FindExecutable()" function to determine if the dependencies have been successfully installed and are identifiable by R. If successful, the output of each .FindExecutable command should list the file location of the program. 

```{r, eval = FALSE}
#library(epictope) # check if epictope is installed and loadable
epictope::.findExecutable("muscle") # looks for muscle executable
# ~/hchung/epictope/bin/muscle" 
epictope::.findExecutable("blastp") # looks for blast executable
# ~/hchung/epictope/bin/blastp" 
epictope::.findExecutable("mkdssp") # looks for dssp executable
# ~/hchung/epictope/bin/mkdssp" 
```

#### Configuration file

`epictope` uses pre-defined values to determine the score and weight of each feature. These values can be adjusted by the user by creating a "config.R" file in the working directory. If a "config.R" file is not found, epictope will use the default values. In either case, the score and weight values are loaded into the environment with the "check_config()".
```{r, eval = FALSE}
check_config()
```

The scores and weights loaded by default are shown below. These settings can be changed by simply copy-pasting the following lines into a "config.R" file, manually adjusting the numbers, and then re-running the check_config() function. 

```{r, eval = FALSE}
# define species to run MSA against
species <- c("bos_taurus", "canis_lupus_familiaris", "gallus_gallus", "homo_sapiens", "mus_musculus", "takifugu_rubripes", "xenopus_tropicalis")

# weights for tagging features
h_weight = 1.5 # shannon entropy
rsa_weight = 1 # solvent accessable surface area
ss_weight = 1 # secondary structure
br_weight = 1 # disordered binding region

# value for secondary structures, must be 0-1.
# each letter refers to a type of secondary structure
# the number indicates the value or "suitability" for tagging.
# values should be from 0-1, with higher values indicating greater
# suitability for tagging.
ss_key <- list(
    "G" = 0, 
    "H" = 0, 
    "I" = 0,
    "E" = 0, 
    "C" = 1,
    "T" = 0.5, 
    "B" = 0.5, 
    "S" = 0.5)

# reference values for maximum solvent accesibility of amino acids.
# default values estimate from the following study;
# https://doi.org/10.1371/journal.pone.0080635
aa <- c("A", "R", "N", "D", "C", "E", "Q", "G", "H", "I", "L", "K", "M", "F", "P", "S", "T", "W", "Y", "V")
empirical <- c(121, 265, 187, 187, 148, 214, 214, 97, 216, 195, 191, 230, 203, 228, 154, 143, 163, 264, 255, 165)
max_sasa <- setNames(empirical, aa)

```

#### Folder structure
The epitope software recommends a specified file structure to store species proteomes and temporary files. This folder structure is outlined as follows;
```{r, eval = FALSE}
project_folder
├── code 
├── config # configuration file for scoring 
├── install.R # helper script
├── single_score.R
├── data
│   ├── CDS # for protein sequences in coding regions for each organism in the MSA
│   └── models # for the predicted alphafold2 structure for a protein of interest
├── outputs # for the output scores
└── README.md
```

To set up this structure, we include a simple function `setup_files` to create this structure for the user. 
```{r, eval = FALSE}
setup_files()
```
### Workflow

Once set up is complete, we can use the package functions to identify optimal tagging locations as follows. To start, we will need to download the protein sequences of the organisms we want to compare against for a multiple sequence alignment. Afterwards, the `data/CDS` folder should be populated with ".gz" files for each of the organisms used in the multiple sequence alignment.


```{r, eval = FALSE}
# search for the default species specified with the config file 
protein_links <- ftp_search(species)
# download the sequences
lapply(protein_links, ftp_download)

# we can also specify the sequences at the time of search 
#protein_links <- ftp_search(species = c("Mus_musculus", "Bos_taurus"))
#lapply(protein_links, ftp_download)
```

Next, we will need to specify the *UniprotID* of the protein you are interested in. UniProt is a freely accessible database of protein sequence and functional information. A single gene can encode multiple protein isoforms through  alternative splicing. Starting with the UniprotID allows to know which specific protein isoform we are interested in and working with. 

```{r, eval = FALSE}
query <- "P57102" # The UniprotID of the protein we are looking for. In this example, we use the Hand2 gene for zebrafish.
uniprot_fields <- c("accession", "id", "gene_names", "xref_alphafolddb", "sequence", "organism_name", "organism_id") # The features for the uniprot id we are interested in retieving. 
uniprot_data <- query_uniProt(query = query, fields = uniprot_fields) # fetch uniprot data
```

Using the Alphafold2ID provided by Uniprot, we can download the Protein Data Bank file or the AlphaFold2 predicted structure for the protein of interest. We then run DSSP to define the secondary structures from the Alphafold2 PDB file and parse out the results to a dataframe.

```{r, eval = FALSE}
# download associated alphafold2 pdb
alphafold_file <- fetch_alphafold(gsub(";", "", uniprot_data$AlphaFoldDB))
# calculate dssp on alphafold2 pdb file
dssp_res <- dssp_command(alphafold_file)
# parse dssp and convert to dataframe
dssp_df <- parse_dssp(dssp_res)
```

The UniprotID is also used for IUPRED2A. IUPred2A is a web interface that allows to identify disordered protein regions using IUPred2 and disordered binding regions using ANCHOR2. From the IUPRED2A output, we take the ANCHOR2 score.
```{r, eval = FALSE}
iupred_df <- iupredAnchor(query) # dataframe for iupred results
```

To perform the multiple sequence alignment (MSA). We must identify homologous proteins in our selected species. To do this, we will BLAST our query protein against the proteome of the selected species. These species can be defined by the user with the "config.R" configuration file, or using the default set of animals. We will sort the BLAST results by their E value, and select highest match by the lowest E value. We will then run muscle to perform the MSA. Using the MSA result, we can calculate the shannnon entropy for each position. 

```{r, eval = FALSE}
# blast query aa sequence
seq <- Biostrings::AAStringSet(uniprot_data$Sequence, start=NA, end=NA, width=NA, use.names=TRUE) # Use the sequence identified by the UniprotID

# list of proteome files to blast against
aa_files <-  list.files(cds_folder, pattern = "\\.all.fa$", full.names = TRUE, recursive = TRUE) # list the protein files in the CDS folder
names(aa_files) <- aa_files # name them to keep track of which animal each result came from

# blast
blast_results <- lapply(aa_files, function(.x){protein_blast(seq, .x)})

# take the highest blast match according to E score 
find_best_match <- function(.x){head(.x[base::order(.x$E),], 1)} # sort by E value and take best match
blast_best_match <- lapply(blast_results, find_best_match) # find best match
blast_seqs <- lapply(blast_best_match, fetch_sequences) # retrieve the sequence for the best match

# Assign the sequence of our query protein to the MSA
blast_seqs[[query]] <- seq
blast_stringset  <- Biostrings::AAStringSet(unlist(lapply(blast_seqs, function(.x){.x[[1]]})))

# multiple sequence alignment
msa_res <-  muscle(blast_stringset)
# shannon entropy calculation
shannon_df <- shannon_reshape(msa_res, query)

```

The final step is to combine the shannon entropy, secondary structure, and disordered binding region into a single dataframe. From there, we can calculate the solvent accessibility and tagging score for each position. The final output will be written to a file in the outputs folder.

```{r, eval = FALSE}
# join tagging features in dataframe
features_df <- Reduce(function(x, y) merge(x, y, all=TRUE), list(shannon_df, dssp_df, iupred_df), accumulate=FALSE)
colnames(features_df)
# normalize features and calculate tagging score
norm_feats_df <- calculate_scores(features_df)
# write to file.
res_df <- merge(norm_feats_df, features_df)
write.csv(apply(res_df,2,as.character), file = paste0(outputFolder, "/", query, "_score.csv"))
```
